{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Applying data minimization to a trained regression ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will show how to perform data minimization for regression ML models using the minimization module.\n",
    "\n",
    "We will show you applying data minimization to a different trained regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data\n",
    "QI parameter determines which features will be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.5, random_state=14)\n",
    "\n",
    "features = ['age', 'sex', 'bmi', 'bp',\n",
    "                's1', 's2', 's3', 's4', 's5', 's6']\n",
    "QI = ['age', 'bmi', 's2', 's5', 's6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train DecisionTreeRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model accuracy (R2 score):  0.15014421352446072\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "apt_path = os.path.abspath(\"/Users/eliandromelo/MSc_CS/ai-privacy-toolkit\")\n",
    "sys.path.append(apt_path)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from apt.minimization import GeneralizeToRepresentative\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model1 = DecisionTreeRegressor(random_state=10, min_samples_split=2)\n",
    "model1.fit(X_train, y_train)\n",
    "print('Base model accuracy (R2 score): ', model1.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run minimization\n",
    "We will try to run minimization with only a subset of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy of model on generalized data, relative to original model predictions (base generalization derived from tree, before improvements): 0.108922\n",
      "Improving accuracy\n",
      "feature to remove: s5\n",
      "Removed feature: s5, new relative accuracy: 0.505498\n",
      "feature to remove: bmi\n",
      "Removed feature: bmi, new relative accuracy: 0.716972\n",
      "Accuracy on minimized data:  0.1116122925781402\n",
      "generalizations:  {'ranges': {'age': [-0.07090024650096893, -0.043656209483742714, -0.041839939542114735, -0.03639113181270659, -0.01459590089507401, -0.012779632292222232, -0.009147093165665865, -0.0036982858437113464, 0.03989217430353165, 0.039892176166176796, 0.05623859912157059, 0.06713621318340302], 's2': [-0.0550188384950161, -0.0285577941685915, -0.024643437936902046, -0.02135537937283516, -0.013683241792023182, -0.006480826530605555, 0.009176596067845821, 0.023111702874302864, 0.02420772146433592, 0.02655633445829153, 0.039082273840904236], 's6': [-0.052854035049676895, -0.03835666086524725, -0.02593033987795934, -0.021788232028484344, -0.01350401807576418, -0.003148751042317599, 0.005135462852194905, 0.01756178360665217, 0.021703890524804592, 0.02998810407007113, 0.03205915819853544, 0.0486275851726532]}, 'categories': {}, 'untouched': ['sex', 'bp', 'bmi', 's1', 's4', 's5', 's3'], 'category_representatives': {}, 'range_representatives': {'age': [-0.07090024650096893, -0.09269547780327612, -0.04910501639104307, 0.0027244038647040725, -0.03820740103798481, -0.027309785684926546, 0.0018162695632781833, -0.009147093429829445, 0.021795230073621497, 0.009015598825267658, 0.008173211477696896, 0.04170844488444244], 's2': [-0.0550188384950161, -0.07239857825244314, -0.03607335668485709, -0.02480001206043385, -0.02448686359864431, -0.014466112821379181, 0.007828711299225688, 0.00463594334778245, 0.019667069513680118, 0.024051147978733624, 0.02499059336410222], 's6': [-0.052854035049676895, -0.06735140813781726, -0.04664087356364498, -0.03835665973397607, -0.025930338989472702, -0.013504018244969336, -0.009361911330134878, -0.0010776975004659671, 0.0113486232440374, 0.004142106772633269, 0.02377494398854077, 0.03205915781820968]}}\n"
     ]
    }
   ],
   "source": [
    "# note that is_regression param is True\n",
    "\n",
    "minimizer1 = GeneralizeToRepresentative(model1, target_accuracy=0.7, is_regression=True,\n",
    "                                    features_to_minimize=QI)\n",
    "\n",
    "# Fitting the minimizar can be done either on training or test data. Doing it with test data is better as the\n",
    "# resulting accuracy on test data will be closer to the desired target accuracy (when working with training\n",
    "# data it could result in a larger gap)\n",
    "# Don't forget to leave a hold-out set for final validation!\n",
    "X_generalizer_train1, x_test1, y_generalizer_train1, y_test1 = train_test_split(X_test, y_test,\n",
    "                                                                test_size = 0.4, random_state = 38)\n",
    "\n",
    "x_train_predictions1 = model1.predict(X_generalizer_train1)\n",
    "minimizer1.fit(X_generalizer_train1, x_train_predictions1, features_names=features)\n",
    "transformed1 = minimizer1.transform(x_test1, features_names=features)\n",
    "print('Accuracy on minimized data: ', model1.score(transformed1, y_test1))\n",
    "print('generalizations: ',minimizer1.generalizations)#%% md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "dlsym(0xec760690, path): symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconcrete\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mapt\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminimization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneralizeToRepresentative\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/concrete/ml/sklearn/__init__.py:11\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebugging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_assert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_true\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     get_model_name,\n\u001b[1;32m      8\u001b[0m     is_classifier_or_partial_classifier,\n\u001b[1;32m      9\u001b[0m     is_regressor_or_partial_regressor,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     12\u001b[0m     _ALL_SKLEARN_MODELS,\n\u001b[1;32m     13\u001b[0m     _LINEAR_MODELS,\n\u001b[1;32m     14\u001b[0m     _NEIGHBORS_MODELS,\n\u001b[1;32m     15\u001b[0m     _NEURALNET_MODELS,\n\u001b[1;32m     16\u001b[0m     _TREE_MODELS,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GammaRegressor, PoissonRegressor, TweedieRegressor\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     ElasticNet,\n\u001b[1;32m     21\u001b[0m     Lasso,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     SGDRegressor,\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/concrete/ml/sklearn/base.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, LogisticRegression\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBModel\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheck_inputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array_and_assert, check_X_y_and_assert_multi_output\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebugging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_assert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_true\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"XGBoost: eXtreme Gradient Boosting library.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mContributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     DMatrix,\n\u001b[1;32m      8\u001b[0m     DeviceQuantileDMatrix,\n\u001b[1;32m      9\u001b[0m     Booster,\n\u001b[1;32m     10\u001b[0m     DataIter,\n\u001b[1;32m     11\u001b[0m     build_info,\n\u001b[1;32m     12\u001b[0m     _py_version,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, cv\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rabit  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/core.py:231\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# load the XGBoost library globally\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m _LIB \u001b[38;5;241m=\u001b[39m _load_lib()\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_call\u001b[39m(ret: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    This function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m        return value from API calls\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/xgboost/core.py:220\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         pyver_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m pyver))\n\u001b[1;32m    216\u001b[0m         libver_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin((\u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m libver))\n\u001b[1;32m    217\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMismatched version between the Python package and the native shared \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mobject.  Python package version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpyver_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Shared object \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m--> 220\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mversion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibver_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Shared object is loaded from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlib\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;124mLikely cause:\u001b[39m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;124m  * XGBoost is first installed with anaconda then upgraded with pip. To fix it \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease remove one of the installations.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         )\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ctypes/__init__.py:392\u001b[0m, in \u001b[0;36mCDLL.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(name)\n\u001b[0;32m--> 392\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(name)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, func)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/ctypes/__init__.py:397\u001b[0m, in \u001b[0;36mCDLL.__getitem__\u001b[0;34m(self, name_or_ordinal)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_ordinal):\n\u001b[0;32m--> 397\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr((name_or_ordinal, \u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name_or_ordinal, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    399\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m name_or_ordinal\n",
      "\u001b[0;31mAttributeError\u001b[0m: dlsym(0xec760690, path): symbol not found"
     ]
    }
   ],
   "source": [
    "from concrete.ml.sklearn.linear_model import LinearRegression\n",
    "from apt.minimization import GeneralizeToRepresentative\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "model2.compile(X_train[:100])\n",
    "y_pred = model2.predict(X_test, fhe=\"execute\")\n",
    "print('Base model accuracy (R2 score): ', r2_score(X_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run minimization\n",
    "We will try to run minimization with only a subset of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy of model on generalized data, relative to original model predictions (base generalization derived from tree, before improvements): -0.030344\n",
      "Improving accuracy\n",
      "feature to remove: s5\n",
      "Removed feature: s5, new relative accuracy: 0.146959\n",
      "feature to remove: s6\n",
      "Removed feature: s6, new relative accuracy: 0.131751\n",
      "feature to remove: age\n",
      "Removed feature: age, new relative accuracy: 0.120796\n",
      "feature to remove: s2\n",
      "Removed feature: s2, new relative accuracy: 0.962978\n",
      "Accuracy on minimized data:  0.46500149833646587\n",
      "generalizations:  {'ranges': {'bmi': [-0.0660245232284069, -0.06171327643096447, -0.048779530450701714, -0.036923596635460854, -0.022912041284143925, -0.01644516922533512, -0.015906263142824173, -0.009978296235203743, 0.007266696775332093, 0.022356065921485424, 0.028822937980294228, 0.04499012045562267, 0.04876246117055416, 0.053073709830641747, 0.09510837681591511, 0.10103634744882584]}, 'categories': {}, 'untouched': ['sex', 'age', 'bp', 's2', 's1', 's6', 's4', 's5', 's3'], 'category_representatives': {}, 'range_representatives': {'bmi': [-0.0660245232284069, -0.09027529589850945, 0.006466872990131378, -0.05794093368208547, -0.04392937672163507, -0.03099563183506548, -0.022373135244019075, 0.002963983453810215, -0.015906262800734303, -0.002972517914164677, 0.0175059114895705, 0.028284032228378497, 0.030439656376140087, 0.04768464955823289, 0.02101733349263668, 0.07031870310972965]}}\n"
     ]
    }
   ],
   "source": [
    "# note that is_regression param is True\n",
    "\n",
    "minimizer2 = GeneralizeToRepresentative(model2, target_accuracy=0.7, is_regression=True,\n",
    "                                    features_to_minimize=QI)\n",
    "\n",
    "# Fitting the minimizar can be done either on training or test data. Doing it with test data is better as the\n",
    "# resulting accuracy on test data will be closer to the desired target accuracy (when working with training\n",
    "# data it could result in a larger gap)\n",
    "# Don't forget to leave a hold-out set for final validation!\n",
    "X_generalizer_train2, x_test2, y_generalizer_train2, y_test2 = train_test_split(X_test, y_test,\n",
    "                                                                test_size = 0.4, random_state = 38)\n",
    "\n",
    "x_train_predictions2 = model2.predict(X_generalizer_train2)\n",
    "minimizer2.fit(X_generalizer_train2, x_train_predictions2, features_names=features)\n",
    "transformed2 = minimizer2.transform(x_test2, features_names=features)\n",
    "print('Accuracy on minimized data: ', model2.score(transformed2, y_test2))\n",
    "print('generalizations: ',minimizer2.generalizations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
